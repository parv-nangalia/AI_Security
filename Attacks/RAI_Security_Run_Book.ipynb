{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "207d5da3-644c-47e2-8d86-3b5b85b870eb",
   "metadata": {},
   "source": [
    "# AI Security"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4046bed2-1f3f-4963-b297-57dd1735baaa",
   "metadata": {},
   "source": [
    "## Adversarial Robustness Toolbox\n",
    "\n",
    "[Adversarial Robustness Toolbox (ART)](https://github.com/Trusted-AI/adversarial-robustness-toolbox)  is a Python library for Machine Learning Security\n",
    "ART provides tools that enable developers and researchers to defend and evaluate Machine Learning models and applications against the adversarial threats of Evasion, Poisoning, Extraction, and Inference. ART supports all popular machine learning frameworks (TensorFlow, Keras, PyTorch, MXNet, scikit-learn, XGBoost, LightGBM, CatBoost, GPy, etc.), all data types (images, tables, audio, video, etc.) and machine learning tasks (classification, object detection, speech recognition, generation, certification, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e3ddc-0ba4-4ceb-940c-3e4128464cf4",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee23eb98-fd45-417a-892c-61dbba69ebc3",
   "metadata": {},
   "source": [
    "#### Installation with pip \n",
    "ART is designed and tested to run with Python 3.\n",
    "\n",
    "ART and its core dependencies (excluding frameworks, e.g. TensorFlow, and tool-specific dependencies, these have to be installed separately or with the install options below) can be installed from the PyPI repository using pip:\n",
    "\n",
    "*Installing the dependencies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e8cc3b-bcbd-472b-b33b-4382964ecc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.python.org/simple"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'D:\\envs\\ai_security\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: adversarial-robustness-toolbox[all] in d:\\envs\\ai_security\\lib\\site-packages (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (1.25.2)\n",
      "Requirement already satisfied: six in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (1.16.0)\n",
      "Requirement already satisfied: tqdm in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (4.66.1)\n",
      "Requirement already satisfied: scikit-learn<1.2.0,>=0.22.2 in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (1.1.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (1.11.3)\n",
      "Requirement already satisfied: setuptools in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (58.1.0)\n",
      "Requirement already satisfied: matplotlib in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (3.8.0)\n",
      "Requirement already satisfied: cma in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (3.3.0)\n",
      "Requirement already satisfied: Pillow in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (10.0.1)\n",
      "Requirement already satisfied: catboost in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (1.2.2)\n",
      "Requirement already satisfied: torch in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (2.1.0)\n",
      "Requirement already satisfied: ffmpeg-python in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (0.2.0)\n",
      "Requirement already satisfied: h5py in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (3.10.0)\n",
      "Requirement already satisfied: mxnet in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (1.2.0)\n",
      "Requirement already satisfied: kornia in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (0.7.0)\n",
      "Requirement already satisfied: opencv-python in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (4.8.1.78)\n",
      "Requirement already satisfied: statsmodels in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (0.14.0)\n",
      "Requirement already satisfied: resampy in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (0.4.2)\n",
      "Requirement already satisfied: torchvision in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (0.16.0)\n",
      "Requirement already satisfied: lightgbm in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (4.1.0)\n",
      "Requirement already satisfied: librosa in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (0.10.1)\n",
      "Requirement already satisfied: numba in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (0.58.0)\n",
      "Requirement already satisfied: tensorflow in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-addons in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (0.21.0)\n",
      "Requirement already satisfied: pandas in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (2.1.1)\n",
      "Requirement already satisfied: xgboost in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (2.0.0)\n",
      "Requirement already satisfied: pydub in d:\\envs\\ai_security\\lib\\site-packages (from adversarial-robustness-toolbox[all]) (0.25.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in d:\\envs\\ai_security\\lib\\site-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox[all]) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\envs\\ai_security\\lib\\site-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox[all]) (3.2.0)\n",
      "Requirement already satisfied: plotly in d:\\envs\\ai_security\\lib\\site-packages (from catboost->adversarial-robustness-toolbox[all]) (5.17.0)\n",
      "Requirement already satisfied: graphviz in d:\\envs\\ai_security\\lib\\site-packages (from catboost->adversarial-robustness-toolbox[all]) (0.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\envs\\ai_security\\lib\\site-packages (from pandas->adversarial-robustness-toolbox[all]) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\envs\\ai_security\\lib\\site-packages (from pandas->adversarial-robustness-toolbox[all]) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\envs\\ai_security\\lib\\site-packages (from pandas->adversarial-robustness-toolbox[all]) (2023.3.post1)\n",
      "Requirement already satisfied: future in d:\\envs\\ai_security\\lib\\site-packages (from ffmpeg-python->adversarial-robustness-toolbox[all]) (0.18.3)\n",
      "Requirement already satisfied: packaging in d:\\envs\\ai_security\\lib\\site-packages (from kornia->adversarial-robustness-toolbox[all]) (23.2)\n",
      "Requirement already satisfied: jinja2 in d:\\envs\\ai_security\\lib\\site-packages (from torch->adversarial-robustness-toolbox[all]) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\envs\\ai_security\\lib\\site-packages (from torch->adversarial-robustness-toolbox[all]) (2023.9.2)\n",
      "Requirement already satisfied: networkx in d:\\envs\\ai_security\\lib\\site-packages (from torch->adversarial-robustness-toolbox[all]) (3.1)\n",
      "Requirement already satisfied: filelock in d:\\envs\\ai_security\\lib\\site-packages (from torch->adversarial-robustness-toolbox[all]) (3.12.4)\n",
      "Requirement already satisfied: sympy in d:\\envs\\ai_security\\lib\\site-packages (from torch->adversarial-robustness-toolbox[all]) (1.12)\n",
      "Requirement already satisfied: typing-extensions in d:\\envs\\ai_security\\lib\\site-packages (from torch->adversarial-robustness-toolbox[all]) (4.8.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in d:\\envs\\ai_security\\lib\\site-packages (from librosa->adversarial-robustness-toolbox[all]) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in d:\\envs\\ai_security\\lib\\site-packages (from librosa->adversarial-robustness-toolbox[all]) (1.0.7)\n",
      "Requirement already satisfied: soxr>=0.3.2 in d:\\envs\\ai_security\\lib\\site-packages (from librosa->adversarial-robustness-toolbox[all]) (0.3.7)\n",
      "Requirement already satisfied: pooch>=1.0 in d:\\envs\\ai_security\\lib\\site-packages (from librosa->adversarial-robustness-toolbox[all]) (1.7.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in d:\\envs\\ai_security\\lib\\site-packages (from librosa->adversarial-robustness-toolbox[all]) (0.12.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in d:\\envs\\ai_security\\lib\\site-packages (from librosa->adversarial-robustness-toolbox[all]) (3.0.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\envs\\ai_security\\lib\\site-packages (from librosa->adversarial-robustness-toolbox[all]) (5.1.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in d:\\envs\\ai_security\\lib\\site-packages (from numba->adversarial-robustness-toolbox[all]) (0.41.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\envs\\ai_security\\lib\\site-packages (from matplotlib->adversarial-robustness-toolbox[all]) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\envs\\ai_security\\lib\\site-packages (from matplotlib->adversarial-robustness-toolbox[all]) (4.43.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\envs\\ai_security\\lib\\site-packages (from matplotlib->adversarial-robustness-toolbox[all]) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\envs\\ai_security\\lib\\site-packages (from matplotlib->adversarial-robustness-toolbox[all]) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\envs\\ai_security\\lib\\site-packages (from matplotlib->adversarial-robustness-toolbox[all]) (1.4.5)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in d:\\envs\\ai_security\\lib\\site-packages (from matplotlib->adversarial-robustness-toolbox[all]) (6.1.0)\n",
      "Requirement already satisfied: requests in d:\\envs\\ai_security\\lib\\site-packages (from mxnet->adversarial-robustness-toolbox[all]) (2.31.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in d:\\envs\\ai_security\\lib\\site-packages (from statsmodels->adversarial-robustness-toolbox[all]) (0.5.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow->adversarial-robustness-toolbox[all]) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (2.14.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (3.3.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (1.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (16.0.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (1.59.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (0.31.0)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (0.2.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (0.5.4)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (23.5.26)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (2.14.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (2.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (0.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (4.24.4)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (2.3.0)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in d:\\envs\\ai_security\\lib\\site-packages (from tensorflow-addons->adversarial-robustness-toolbox[all]) (2.13.3)\n",
      "Requirement already satisfied: colorama in d:\\envs\\ai_security\\lib\\site-packages (from tqdm->adversarial-robustness-toolbox[all]) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\envs\\ai_security\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->adversarial-robustness-toolbox[all]) (3.17.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in d:\\envs\\ai_security\\lib\\site-packages (from pooch>=1.0->librosa->adversarial-robustness-toolbox[all]) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\envs\\ai_security\\lib\\site-packages (from requests->mxnet->adversarial-robustness-toolbox[all]) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\envs\\ai_security\\lib\\site-packages (from requests->mxnet->adversarial-robustness-toolbox[all]) (2.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\envs\\ai_security\\lib\\site-packages (from requests->mxnet->adversarial-robustness-toolbox[all]) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\envs\\ai_security\\lib\\site-packages (from requests->mxnet->adversarial-robustness-toolbox[all]) (2023.7.22)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\envs\\ai_security\\lib\\site-packages (from soundfile>=0.12.1->librosa->adversarial-robustness-toolbox[all]) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\envs\\ai_security\\lib\\site-packages (from jinja2->torch->adversarial-robustness-toolbox[all]) (2.1.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in d:\\envs\\ai_security\\lib\\site-packages (from plotly->catboost->adversarial-robustness-toolbox[all]) (8.2.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\envs\\ai_security\\lib\\site-packages (from sympy->torch->adversarial-robustness-toolbox[all]) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\envs\\ai_security\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (0.41.2)\n",
      "Requirement already satisfied: pycparser in d:\\envs\\ai_security\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->adversarial-robustness-toolbox[all]) (2.21)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\envs\\ai_security\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (2.23.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\envs\\ai_security\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (3.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\envs\\ai_security\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (3.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\envs\\ai_security\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (0.7.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in d:\\envs\\ai_security\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (1.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\envs\\ai_security\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\envs\\ai_security\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\envs\\ai_security\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (5.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\envs\\ai_security\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\envs\\ai_security\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (6.8.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in d:\\envs\\ai_security\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\envs\\ai_security\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->adversarial-robustness-toolbox[all]) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install adversarial-robustness-toolbox[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d33d83-8c85-411d-a584-910cadf76bf0",
   "metadata": {},
   "source": [
    "# Adversarial Robustness Toolbox examples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e167a35-b15d-455b-8aca-4a8f0e133022",
   "metadata": {},
   "source": [
    "## Get Started with ART\n",
    "\n",
    "# Imperceptible attack on tabular data using LowProFool algorithm\n",
    "\n",
    "In this notebook, we will learn how to execute imperceptible attack on tabular data with the LowProFool algorithm (https://arxiv.org/abs/1911.03274). We will use iris flowers and breast cancer datasetsrts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906a4c38-67d6-4cb3-a78a-0d18085e49bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8574ff-f3e8-4fcf-8ab8-7ac8ccb6e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.classification.scikitlearn import ScikitlearnLogisticRegression\n",
    "from art.estimators.classification.pytorch import PyTorchClassifier\n",
    "from art.attacks.evasion import LowProFool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc1991b-121b-4a62-87ff-b605b7bd6920",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data preparation\n",
    "Firstly, we load the datasets, standardize them, and split into training and validation sets. We also choose the clipping values for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d989d3ab-b3de-4545-a867-8b422965e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data):\n",
    "    \"\"\"\n",
    "    Get both the standardized data and the used scaler.\n",
    "    \"\"\"\n",
    "    columns = data.columns\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(data)\n",
    "    \n",
    "    return pd.DataFrame(data=x_scaled, columns=columns), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14626414-c65a-46fd-841f-ee5ad0f5dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "\n",
    "def get_train_and_valid(design_matrix, labels):\n",
    "    \"\"\"\n",
    "    Split dataset into training and validation sets.\n",
    "    \"\"\"\n",
    "    for train_idx, valid_idx in split.split(design_matrix, labels):\n",
    "        X_train = design_matrix.iloc[train_idx].copy()\n",
    "        X_valid = design_matrix.iloc[valid_idx].copy()\n",
    "        y_train = labels.iloc[train_idx].copy()\n",
    "        y_valid = labels.iloc[valid_idx].copy()\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5420262d-14da-41d2-9898-daf475e580dc",
   "metadata": {},
   "source": [
    "### Loading and preparation of the iris flowers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b90d2b-5451-479e-b047-4b9ae7be57e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\parv.nangalia\\Desktop\\AIHackathon\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\Users\\parv.nangalia\\Desktop\\AIHackathon\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\parv.nangalia\\Desktop\\AIHackathon\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\parv.nangalia\\Desktop\\AIHackathon\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\Users\\parv.nangalia\\Desktop\\AIHackathon\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\parv.nangalia\\Desktop\\AIHackathon\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "design_matrix_iris = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
    "labels_iris = pd.Series(data=iris['target'])\n",
    "display(design_matrix_iris)\n",
    "\n",
    "design_matrix_iris_scaled, iris_scaler = standardize(design_matrix_iris)\n",
    "\n",
    "X_train_iris, y_train_iris, X_valid_iris, y_valid_iris =\\\n",
    "    get_train_and_valid(design_matrix_iris_scaled, labels_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c96336e-c6ec-4e78-a0ae-acbe3aa2b563",
   "metadata": {},
   "source": [
    "### Loading and preparation of the breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "171ed8ac-41e6-4497-a172-284eca2df179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\parv.nangalia\\Desktop\\AIHackathon\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\Users\\parv.nangalia\\Desktop\\AIHackathon\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\parv.nangalia\\Desktop\\AIHackathon\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\parv.nangalia\\Desktop\\AIHackathon\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\Users\\parv.nangalia\\Desktop\\AIHackathon\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\parv.nangalia\\Desktop\\AIHackathon\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "design_matrix_cancer = pd.DataFrame(data=cancer['data'], columns=cancer['feature_names'])\n",
    "labels_cancer = pd.Series(data=cancer['target'])\n",
    "display(design_matrix_cancer)\n",
    "\n",
    "design_matrix_cancer_scaled, cancer_scaler = standardize(design_matrix_cancer)\n",
    "\n",
    "X_train_cancer, y_train_cancer, X_valid_cancer, y_valid_cancer =\\\n",
    "    get_train_and_valid(design_matrix_cancer_scaled, labels_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f46bbb-53db-44d4-b5e0-61bec704ab3d",
   "metadata": {},
   "source": [
    "#### Clip-values\n",
    "**Iris flowers dataset** - minimum and maximum values in training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92d0c2de-ff0c-419e-98a9-8072d6c419c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clip-values:\n",
      "  Lower bound: [-1.87002413 -2.43394714 -1.56757623 -1.44707648]\n",
      "  Upper bound: [2.4920192  3.09077525 1.78583195 1.71209594]\n",
      "\n",
      "Clip-values in original scale:\n",
      "  Lower bound: [4.3 2.  1.  0.1]\n",
      "  Upper bound: [7.9 4.4 6.9 2.5]\n"
     ]
    }
   ],
   "source": [
    "scaled_clip_values_iris = (\n",
    "    np.array(X_train_iris.min()),\n",
    "    np.array(X_train_iris.max())\n",
    ")\n",
    "print(\"Clip-values:\")\n",
    "print(\"  Lower bound:\", scaled_clip_values_iris[0])\n",
    "print(\"  Upper bound:\", scaled_clip_values_iris[1])\n",
    "\n",
    "print(\"\\nClip-values in original scale:\")\n",
    "clip_values_iris = iris_scaler.inverse_transform(scaled_clip_values_iris)\n",
    "print(\"  Lower bound:\", clip_values_iris[0])\n",
    "print(\"  Upper bound:\", clip_values_iris[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a979aa6f-65a3-4547-beef-181a863c02c8",
   "metadata": {},
   "source": [
    "**Breast cancer dataset** - 1 standard deviation boundary.\n",
    "\n",
    "Note: Here, we create clip values such that all values should fall within the one standard deviation interval. Thanks to the dataset being priorly standardized, it is a trivial problem. Moreover clip values can be concisely expressed as just a single tuple (-1., 1.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34c590c0-b4ec-4e1f-b485-6acdc45ecf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_clip_values_cancer = (-1., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb181484-5506-4eb1-8b18-4f321337632c",
   "metadata": {},
   "source": [
    "As you can see, one can easily generate good quality adversary examples in just a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abfef12-51dd-4153-bad9-8e8b6a56d2c0",
   "metadata": {},
   "source": [
    "----\n",
    "# LowProFool example\n",
    "In this section, we present you a few examples of LowProFool adversarial attacks carried out in a similar fashion, but employing different underlying models and on different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1e740-ae0f-4bdc-8e17-f3d729e0ec7c",
   "metadata": {},
   "source": [
    "\n",
    "## Preparation of classifiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6121d4-9aaf-4538-90d6-4280606c139c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b5b620-8c57-4fc9-a6d5-2940c877287a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Training on iris flowers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba391791-a438-4a64-bced-b9d2d063963f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regression_clf_iris = LogisticRegression()\n",
    "log_regression_clf_iris.fit(X_train_iris.values, y_train_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dea1114e-5b84-4ae9-938b-554e6e1dd312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regression_clf_cancer = LogisticRegression()\n",
    "log_regression_clf_cancer.fit(X_train_cancer.values, y_train_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366e9078-d168-4bd7-81dc-7c587ed98f7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cee7c122-3fb8-4716-a94e-ee35cfefee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_model(input_dimensions, hidden_neurons, output_dimensions):\n",
    "    \"\"\"\n",
    "    Prepare PyTorch (torch) neural network.\n",
    "    \"\"\"\n",
    "    return torch.nn.Sequential(\n",
    "        nn.Linear(input_dimensions, hidden_neurons),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_neurons, output_dimensions),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "def train_nn(nn_model, X, y, learning_rate, epochs):\n",
    "    \"\"\"\n",
    "    Train provided neural network.\n",
    "    \"\"\"\n",
    "    optimizer = optim.SGD(nn_model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        y_pred = nn_model.forward(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        nn_model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5021047c-978d-4552-bd19-20da352a7754",
   "metadata": {},
   "source": [
    "#### Training on iris flowers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78d0b7c4-f125-4612-9fa1-d43b856b6790",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Variable(torch.FloatTensor(np.array(X_train_iris)))\n",
    "y = Variable(torch.FloatTensor(np.eye(3)[y_train_iris]))\n",
    "nn_model_iris = get_nn_model(4, 10, 3)\n",
    "train_nn(nn_model_iris, X, y, 1e-4, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21680661-8a2a-4a9e-ac7b-02c974960831",
   "metadata": {},
   "source": [
    "#### Training on breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cbfe6e1-c61e-491b-931d-e0971f9eac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Variable(torch.FloatTensor(np.array(X_train_cancer.values)))\n",
    "y = Variable(torch.FloatTensor(np.eye(2)[y_train_cancer]))\n",
    "nn_model_cancer = get_nn_model(30, 50, 2)\n",
    "train_nn(nn_model_cancer, X, y, 1e-4, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99803f24-7aad-4fb9-8ad8-62c3e204d76e",
   "metadata": {},
   "source": [
    "## Actual usage of LowProFool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b805881-2b90-4cf9-8625-8c817e06a4f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e4332fb-4403-4c98-a695-8d02c4660c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowprofool_generate_adversaries_test_lr(lowprofool, classifier, x_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Testing utility.\n",
    "    \"\"\"\n",
    "    n_classes = lowprofool.n_classes\n",
    "    \n",
    "    # Generate targets\n",
    "    target = np.eye(n_classes)[np.array(\n",
    "        y_valid.apply(\n",
    "            lambda x: np.random.choice([i for i in range(n_classes) if i != x]))\n",
    "    )]\n",
    "    \n",
    "    # Generate adversaries\n",
    "    adversaries = lowprofool.generate(x=x_valid, y=target)\n",
    "\n",
    "    # Test - check the success rate\n",
    "    expected = np.argmax(target, axis=1)\n",
    "    predicted = np.argmax(classifier.predict_proba(adversaries), axis=1)\n",
    "    correct = (expected == predicted)\n",
    "    \n",
    "    success_rate = np.sum(correct) / correct.shape[0]\n",
    "    print(\"Success rate: {:.2f}%\".format(100*success_rate))\n",
    "    \n",
    "    return adversaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f50e62-c03d-492b-9ad6-11e5f8f4a5e5",
   "metadata": {},
   "source": [
    "#### Iris flowers dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "065e2e75-cb21-4310-806d-5d704c3d24d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Wrapping classifier into appropriate ART-friendly wrapper\n",
    "logistic_regression_iris_wrapper = ScikitlearnLogisticRegression(\n",
    "    model       = log_regression_clf_iris, \n",
    "    clip_values = scaled_clip_values_iris\n",
    ")\n",
    "\n",
    "# Creating LowProFool instance\n",
    "lpf_logistic_regression_iris = LowProFool(\n",
    "    classifier = logistic_regression_iris_wrapper, \n",
    "    eta        = 5,\n",
    "    lambd      = 0.2, \n",
    "    eta_decay  = 0.9\n",
    ")\n",
    "\n",
    "# Fitting feature importance\n",
    "lpf_logistic_regression_iris.fit_importances(X_train_iris, y_train_iris)\n",
    "\n",
    "# Testing\n",
    "results_lr_ir = lowprofool_generate_adversaries_test_lr(\n",
    "    lowprofool = lpf_logistic_regression_iris,\n",
    "    classifier = log_regression_clf_iris, \n",
    "    x_valid    = X_valid_iris, \n",
    "    y_valid    = y_valid_iris\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded463ef-4ba0-4545-957a-e0ee3f08f374",
   "metadata": {},
   "source": [
    "Successful adversarial attack. Below we can see the original features and their classes, as well as the adversaries generated by LowProFool and predicted class-wise probabilities of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b77c613-e6b3-4162-b85b-d72a0cf3297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predictions(values, preds, max_features=4):\n",
    "    \"\"\"\n",
    "    Utility function for printing predictions.\n",
    "    \"\"\"\n",
    "    predictions = zip(list(map(lambda e: e[:max_features], values.tolist())), preds.tolist())\n",
    "    \n",
    "    for features, pred in predictions:\n",
    "        print(\"Features[:{}]:\".format(max_features))\n",
    "        for i, val in enumerate(features):\n",
    "            if i % 6 != 5: print(\"{:>10.4f}\".format(val), end='')\n",
    "            else:          print(\"{:>10.4f}\\n\".format(val), end='')\n",
    "        if len(features) % 6 != 0: print()\n",
    "        \n",
    "        print(\"Prediction (probability -> class):\")\n",
    "        for val in pred:\n",
    "            print(\"{:>8.3f}\".format(val), end='')\n",
    "        print(\"  ->  {}\\n\".format(np.argmax(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c196ac4d-9850-4d9f-b045-dd98cc05dfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Original values ===\n",
      "\n",
      "Features[:4]:\n",
      "    6.3000    3.3000    6.0000    2.5000\n",
      "Prediction (probability -> class):\n",
      "   0.000   0.010   0.989  ->  2\n",
      "\n",
      "Features[:4]:\n",
      "    5.1000    3.5000    1.4000    0.2000\n",
      "Prediction (probability -> class):\n",
      "   0.983   0.017   0.000  ->  0\n",
      "\n",
      "Features[:4]:\n",
      "    4.9000    3.1000    1.5000    0.1000\n",
      "Prediction (probability -> class):\n",
      "   0.957   0.043   0.000  ->  0\n",
      "\n",
      "\n",
      "=== Adversaries (LowProFool results) ===\n",
      "\n",
      "Features[:4]:\n",
      "    7.8893    2.6554    5.1651    1.0961\n",
      "Prediction (probability -> class):\n",
      "   0.000   0.866   0.134  ->  1\n",
      "\n",
      "Features[:4]:\n",
      "    6.9759    2.2792    6.3187    2.3087\n",
      "Prediction (probability -> class):\n",
      "   0.000   0.007   0.993  ->  2\n",
      "\n",
      "Features[:4]:\n",
      "    6.7293    2.0210    6.3154    2.2818\n",
      "Prediction (probability -> class):\n",
      "   0.000   0.007   0.993  ->  2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\envs\\ai_security\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\envs\\ai_security\\lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "D:\\envs\\ai_security\\lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "D:\\envs\\ai_security\\lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Original values ===\\n\")\n",
    "\n",
    "print_predictions(iris_scaler.inverse_transform(X_valid_iris[-3:].values), \n",
    "    log_regression_clf_iris.predict_proba(X_valid_iris[-3:]))\n",
    "    \n",
    "print(\"\\n=== Adversaries (LowProFool results) ===\\n\")\n",
    "    \n",
    "print_predictions(iris_scaler.inverse_transform(results_lr_ir[-3:]), \n",
    "    log_regression_clf_iris.predict_proba(results_lr_ir[-3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938ba1c6-f8fe-4e3d-9d1d-2c08260f066b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Breast cancer dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "533ab460-6009-4d6a-abd3-c6dda9fe3b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Wrapping classifier into appropriate ART-friendly wrapper\n",
    "logistic_regression_cancer_wrapper = ScikitlearnLogisticRegression(\n",
    "    model       = log_regression_clf_cancer, \n",
    "    clip_values = scaled_clip_values_cancer\n",
    ")\n",
    "\n",
    "# Creating LowProFool instance\n",
    "lpf_logistic_regression_cancer = LowProFool(\n",
    "    classifier = logistic_regression_cancer_wrapper, \n",
    "    eta        = 5,\n",
    "    lambd      = 0.2, \n",
    "    eta_decay  = 0.9\n",
    ")\n",
    "\n",
    "# Fitting feature importance\n",
    "lpf_logistic_regression_cancer.fit_importances(X_train_cancer, y_train_cancer)\n",
    "\n",
    "# Testing\n",
    "results_lr_bc = lowprofool_generate_adversaries_test_lr(\n",
    "    lowprofool = lpf_logistic_regression_cancer,\n",
    "    classifier = log_regression_clf_cancer, \n",
    "    x_valid    = X_valid_cancer, \n",
    "    y_valid    = y_valid_cancer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eb4e78b-bd85-4bcc-add8-9119238ad1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Original values ===\n",
      "\n",
      "Features[:30]:\n",
      "   12.8700   19.5400   82.6700  509.2000    0.0914    0.0788\n",
      "    0.0180    0.0209    0.1861    0.0635    0.3665    0.7693\n",
      "    2.5970   26.5000    0.0059    0.0136    0.0071    0.0065\n",
      "    0.0222    0.0024   14.4500   24.3800   95.1400  626.9000\n",
      "    0.1214    0.1652    0.0713    0.0638    0.3313    0.0774\n",
      "Prediction (probability -> class):\n",
      "   0.006   0.994  ->  1\n",
      "\n",
      "Features[:30]:\n",
      "   11.8100   17.3900   75.2700  428.9000    0.1007    0.0556\n",
      "    0.0235    0.0155    0.1718    0.0578    0.1859    1.9260\n",
      "    1.0110   14.4700    0.0078    0.0088    0.0156    0.0062\n",
      "    0.0314    0.0020   12.5700   26.4800   79.5700  489.5000\n",
      "    0.1356    0.1000    0.0880    0.0431    0.3200    0.0658\n",
      "Prediction (probability -> class):\n",
      "   0.000   1.000  ->  1\n",
      "\n",
      "\n",
      "=== Adversaries (LowProFool results) ===\n",
      "\n",
      "Features[:30]:\n",
      "   17.6168   23.5787  116.0187 1003.4447    0.0997    0.0517\n",
      "    0.1675    0.0872    0.1735    0.0557    0.6810    0.7894\n",
      "    4.8775   85.5782    0.0085    0.0076    0.0017    0.0179\n",
      "    0.0123    0.0012   21.0495   31.7998  140.4935 1444.1356\n",
      "    0.1551    0.3039    0.4784    0.1794    0.3519    0.1020\n",
      "Prediction (probability -> class):\n",
      "   1.000   0.000  ->  0\n",
      "\n",
      "Features[:30]:\n",
      "   17.6098   23.5744  115.9685 1002.9523    0.1091    0.0516\n",
      "    0.1675    0.0871    0.1591    0.0557    0.6803    1.7680\n",
      "    4.8715   85.5356    0.0100    0.0076    0.0039    0.0179\n",
      "    0.0137    0.0012   21.0357   31.8050  140.3774 1443.2493\n",
      "    0.1551    0.2395    0.4785    0.1792    0.3518    0.1019\n",
      "Prediction (probability -> class):\n",
      "   1.000   0.000  ->  0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\envs\\ai_security\\lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "D:\\envs\\ai_security\\lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "D:\\envs\\ai_security\\lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "D:\\envs\\ai_security\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\envs\\ai_security\\lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "D:\\envs\\ai_security\\lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "D:\\envs\\ai_security\\lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Original values ===\\n\")\n",
    "\n",
    "print_predictions(cancer_scaler.inverse_transform(X_valid_cancer[-2:]), \n",
    "                  log_regression_clf_cancer.predict_proba(X_valid_cancer[-2:]), max_features=30)\n",
    "\n",
    "print(\"\\n=== Adversaries (LowProFool results) ===\\n\")\n",
    "\n",
    "print_predictions(cancer_scaler.inverse_transform(results_lr_bc[-2:]), \n",
    "                  log_regression_clf_cancer.predict_proba(results_lr_bc[-2:]), max_features=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c764706-c100-4cc6-b995-b42e0bc0d3d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38f7aea7-7f41-4448-85cb-6d92ec47a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowprofool_generate_adversaries_test_nn(lowprofool, classifier, x_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Testing utility.\n",
    "    \"\"\"\n",
    "    n_classes = lowprofool.n_classes\n",
    "    \n",
    "    # Generate targets\n",
    "    target = np.eye(n_classes)[np.array(\n",
    "        y_valid.apply(\n",
    "            lambda x: np.random.choice([i for i in range(n_classes) if i != x]))\n",
    "    )]\n",
    "    \n",
    "    # Generate adversaries\n",
    "    adversaries = lowprofool.generate(x=x_valid, y=target)\n",
    "\n",
    "    # Test - check the success rate\n",
    "    expected = np.argmax(target, axis=1)\n",
    "    x = Variable(torch.from_numpy(adversaries.astype(np.float32)))\n",
    "    predicted = np.argmax(classifier.forward(x).detach().numpy(), axis=1)\n",
    "    correct = (expected == predicted)\n",
    "    \n",
    "    success_rate = np.sum(correct) / correct.shape[0]\n",
    "    print(\"Success rate: {:.2f}%\".format(100*success_rate))\n",
    "    \n",
    "    return adversaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ca910-cf1f-4864-9bf4-2e567db07772",
   "metadata": {},
   "source": [
    "#### Iris flowers dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c87c0420-a552-48f0-b896-5c0ec457e254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Wrapping classifier into appropriate ART-friendly wrapper\n",
    "# (in this case it is PyTorch NN classifier wrapper from ART)\n",
    "neural_network_iris_wrapper = PyTorchClassifier(\n",
    "    model       = nn_model_iris, \n",
    "    loss        = loss_fn,\n",
    "    input_shape = (4,),\n",
    "    nb_classes  = 3,\n",
    "    clip_values = scaled_clip_values_iris\n",
    ")\n",
    "\n",
    "# Creating LowProFool instance\n",
    "lpf_neural_network_iris = LowProFool(\n",
    "    classifier = neural_network_iris_wrapper,\n",
    "    n_steps    = 100,\n",
    "    eta        = 7,\n",
    "    lambd      = 1.75, \n",
    "    eta_decay  = 0.95\n",
    ")\n",
    "\n",
    "# Fitting feature importance\n",
    "lpf_neural_network_iris.fit_importances(X_train_iris, y_train_iris)\n",
    "\n",
    "# Testing\n",
    "results_nn_ir = lowprofool_generate_adversaries_test_nn(\n",
    "    lowprofool = lpf_neural_network_iris,\n",
    "    classifier = nn_model_iris, \n",
    "    x_valid    = X_valid_iris, \n",
    "    y_valid    = y_valid_iris\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f1b81f6-5f02-466d-a48c-bb2ce22d0529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Original values ===\n",
      "\n",
      "Features[:4]:\n",
      "    5.5000    3.5000    1.3000    0.2000\n",
      "Prediction (probability -> class):\n",
      "   0.949   0.043   0.008  ->  0\n",
      "\n",
      "Features[:4]:\n",
      "    5.7000    2.8000    4.5000    1.3000\n",
      "Prediction (probability -> class):\n",
      "   0.139   0.575   0.286  ->  1\n",
      "\n",
      "Features[:4]:\n",
      "    5.1000    3.8000    1.9000    0.4000\n",
      "Prediction (probability -> class):\n",
      "   0.950   0.041   0.009  ->  0\n",
      "\n",
      "\n",
      "=== Adversaries (LowProFool results) ===\n",
      "\n",
      "Features[:4]:\n",
      "    7.0219    3.6927    4.3126    2.3001\n",
      "Prediction (probability -> class):\n",
      "   0.030   0.180   0.790  ->  2\n",
      "\n",
      "Features[:4]:\n",
      "    6.5403    3.2033    6.2379    2.3576\n",
      "Prediction (probability -> class):\n",
      "   0.020   0.140   0.840  ->  2\n",
      "\n",
      "Features[:4]:\n",
      "    4.7723    2.2178    3.7398    0.6132\n",
      "Prediction (probability -> class):\n",
      "   0.218   0.637   0.145  ->  1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Original values ===\\n\")\n",
    "\n",
    "print_predictions(iris_scaler.inverse_transform(X_valid_iris[:3].values),\n",
    "      neural_network_iris_wrapper.predict(X_valid_iris[:3].values.astype(np.float32)))\n",
    "\n",
    "print(\"\\n=== Adversaries (LowProFool results) ===\\n\")\n",
    "\n",
    "print_predictions(iris_scaler.inverse_transform(results_nn_ir[:3]), \n",
    "      neural_network_iris_wrapper.predict(results_nn_ir.astype(np.float32)[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d322e9-defb-4b07-b03b-2e31cd73b59b",
   "metadata": {},
   "source": [
    "#### Breast cancer dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d763a579-2806-4e88-bf46-39321fce5f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 98.25%\n"
     ]
    }
   ],
   "source": [
    "# Wrapping classifier into appropriate ART-friendly wrapper\n",
    "# (in this case it is PyTorch NN classifier wrapper from ART)\n",
    "neural_network_cancer_wrapper = PyTorchClassifier(\n",
    "    model       = nn_model_cancer, \n",
    "    loss        = loss_fn, \n",
    "    input_shape = (30,),\n",
    "    nb_classes  = 2,\n",
    "    clip_values = scaled_clip_values_cancer\n",
    ")\n",
    "\n",
    "# Creating LowProFool instance\n",
    "lpf_neural_network_cancer = LowProFool(\n",
    "    classifier = neural_network_cancer_wrapper,\n",
    "    n_steps    = 200,\n",
    "    eta        = 10,\n",
    "    lambd      = 2, \n",
    "    eta_decay  = 0.99\n",
    ")\n",
    "\n",
    "# Fitting feature importance\n",
    "lpf_neural_network_cancer.fit_importances(X_train_cancer, y_train_cancer)\n",
    "\n",
    "# Testing\n",
    "results_nn_bc = lowprofool_generate_adversaries_test_nn(\n",
    "    lowprofool = lpf_neural_network_cancer,\n",
    "    classifier = nn_model_cancer, \n",
    "    x_valid    = X_valid_cancer, \n",
    "    y_valid    = y_valid_cancer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7a88bac-d66b-4b7c-a8ca-c40bea8f9024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Original values ===\n",
      "\n",
      "Features[:30]:\n",
      "   12.8700   19.5400   82.6700  509.2000    0.0914    0.0788\n",
      "    0.0180    0.0209    0.1861    0.0635    0.3665    0.7693\n",
      "    2.5970   26.5000    0.0059    0.0136    0.0071    0.0065\n",
      "    0.0222    0.0024   14.4500   24.3800   95.1400  626.9000\n",
      "    0.1214    0.1652    0.0713    0.0638    0.3313    0.0774\n",
      "Prediction (probability -> class):\n",
      "   0.015   0.985  ->  1\n",
      "\n",
      "Features[:30]:\n",
      "   11.8100   17.3900   75.2700  428.9000    0.1007    0.0556\n",
      "    0.0235    0.0155    0.1718    0.0578    0.1859    1.9260\n",
      "    1.0110   14.4700    0.0078    0.0088    0.0156    0.0062\n",
      "    0.0314    0.0020   12.5700   26.4800   79.5700  489.5000\n",
      "    0.1356    0.1000    0.0880    0.0431    0.3200    0.0658\n",
      "Prediction (probability -> class):\n",
      "   0.005   0.995  ->  1\n",
      "\n",
      "\n",
      "=== Adversaries (LowProFool results) ===\n",
      "\n",
      "Features[:30]:\n",
      "   14.0018   22.8150   90.9044  695.5413    0.1057    0.0870\n",
      "    0.0514    0.0325    0.1634    0.0557    0.5360    1.2544\n",
      "    3.8995   49.1431    0.0061    0.0076    0.0231    0.0084\n",
      "    0.0123    0.0012   17.4891   31.5555  110.6408  887.3389\n",
      "    0.1509    0.2608    0.2356    0.0961    0.3519    0.0696\n",
      "Prediction (probability -> class):\n",
      "   0.975   0.025  ->  0\n",
      "\n",
      "Features[:30]:\n",
      "   13.5471   20.9680   89.3332  744.3549    0.1104    0.0705\n",
      "    0.0617    0.0321    0.1698    0.0557    0.5045    1.6305\n",
      "    2.9517   43.9876    0.0077    0.0076    0.0064    0.0085\n",
      "    0.0190    0.0012   17.9325   31.8181  108.1374  901.0498\n",
      "    0.1552    0.2094    0.3424    0.0977    0.3519    0.0659\n",
      "Prediction (probability -> class):\n",
      "   0.969   0.031  ->  0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\envs\\ai_security\\lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "D:\\envs\\ai_security\\lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "D:\\envs\\ai_security\\lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Original values ===\\n\")\n",
    "\n",
    "print_predictions(\n",
    "    cancer_scaler.inverse_transform(X_valid_cancer[-2:]),\n",
    "    neural_network_cancer_wrapper.predict(X_valid_cancer[-2:].values.astype(np.float32)),\n",
    "    max_features=30\n",
    ")\n",
    "\n",
    "print(\"\\n=== Adversaries (LowProFool results) ===\\n\")\n",
    "\n",
    "print_predictions(\n",
    "    cancer_scaler.inverse_transform(results_nn_bc[-2:]), \n",
    "    neural_network_cancer_wrapper.predict(results_nn_bc.astype(np.float32)[-2:]),\n",
    "    max_features=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb652cbf-8a46-4062-be7a-dd2b195f934e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d409d585-b19f-45de-8d81-ed79a31f2d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
